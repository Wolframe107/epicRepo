{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bigX58Mq0HCG"
      },
      "source": [
        "#Project 1: DCT Compression of an Intraframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIA70xWY0Uba"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "In Project 1, we are going to implement an intraframe compression\n",
        "process via DCT transformation and quantization. Specifically, this\n",
        "process is realized by:\n",
        "1. Segmenting an intraframe image into patches\n",
        "2. Converting each image patch into DCT coefficients\n",
        "3. Quantizing the DCT coefficients.\n",
        "You also need to reconstruct the compressed frame via a reverse\n",
        "process: inverse DCT transform of each compressed patch by using\n",
        "quantized DCT coefficients and regroup them back to a frame.\n",
        "\n",
        "Please follow these steps to prepare for the tasks:\n",
        "1. Download the given video file in the course files and add it to the project files.\n",
        "2. Import the libraries below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Anfe403Uzwnc"
      },
      "outputs": [],
      "source": [
        "#LIBRARIES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pylab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzX6SJH0ctA"
      },
      "source": [
        "#Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCBdHmTN-84U"
      },
      "source": [
        "Task 0. A piece of cake\n",
        "\n",
        "1. Extract frame number 80 from the video file\n",
        "2. Convert the frame from RGB to YUV by using your function\n",
        "“frameRGB2YUV”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JWO7Tj_V-5Wy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-47.91944023 -47.91944023 -47.91944023 -47.91944023 -47.91944023\n",
            "  -47.91944023 -47.91944023 -47.91944023]\n",
            " [-48.2361866  -48.2361866  -48.2361866  -48.2361866  -48.2361866\n",
            "  -48.2361866  -48.2361866  -48.2361866 ]\n",
            " [-48.82145756 -48.82145756 -48.82145756 -48.82145756 -48.82145756\n",
            "  -48.82145756 -48.82145756 -48.82145756]\n",
            " [-49.58615093 -49.58615093 -49.58615093 -49.58615093 -49.58615093\n",
            "  -49.58615093 -49.58615093 -49.58615093]\n",
            " [-50.41384907 -50.41384907 -50.41384907 -50.41384907 -50.41384907\n",
            "  -50.41384907 -50.41384907 -50.41384907]\n",
            " [-51.17854244 -51.17854244 -51.17854244 -51.17854244 -51.17854244\n",
            "  -51.17854244 -51.17854244 -51.17854244]\n",
            " [-51.7638134  -51.7638134  -51.7638134  -51.7638134  -51.7638134\n",
            "  -51.7638134  -51.7638134  -51.7638134 ]\n",
            " [-52.08055977 -52.08055977 -52.08055977 -52.08055977 -52.08055977\n",
            "  -52.08055977 -52.08055977 -52.08055977]]\n"
          ]
        }
      ],
      "source": [
        "#VIDEO\n",
        "\n",
        "# Here are the additional functions you will need to call in this lab\n",
        "# y = Diffimage(x1, x2)\n",
        "# y = Reconsimage(x1, x2)\n",
        "\n",
        "cap = cv2.VideoCapture('test_video.mp4')\n",
        "\n",
        "if cap.isOpened() == False:\n",
        "    print(\"That's probably not the name of your clip\")\n",
        "\n",
        "# Some information about the video file\n",
        "cap_e = int(cap.get(0)) # Elapsed video time in milliseconds\n",
        "cap_w = int(cap.get(3)) # Frame width\n",
        "cap_h = int(cap.get(4)) # Frame height\n",
        "cap_r = int(cap.get(5)) # Frame rate\n",
        "cap_l = int(cap.get(7)) # Length in number of frames\n",
        "# Under VideoCapture::get is a list of attributes\n",
        "# https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-open\n",
        "\n",
        "stop = 80\n",
        "\n",
        "for i in range(stop):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if i == stop-1:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        YUVframe = np.rint(frameRGB2YUV(frame))\n",
        "        frame_80 = abs(YUVframe[:,:,0])\n",
        "\n",
        "patches = Cutimage(frame_80)\n",
        "\n",
        "for patch in patches:\n",
        "    conv_patch = DCTconv(patch)\n",
        "    recon_patch = iDCTconv(conv_patch)\n",
        "\n",
        "print(recon_patch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ebMYGhaC_CoH"
      },
      "outputs": [],
      "source": [
        "#RGB2YUV\n",
        "\n",
        "def frameRGB2YUV(RGBframe):\n",
        "  # Transform RGB to YUV\n",
        "  imagearray = np.array(RGBframe)\n",
        "  imagearray = imagearray.astype(\"uint8\")\n",
        "  transform_matrix = np.array([[0.2126, 0.7152, 0.0722], [-0.09991, -0.33609, 0.436], [0.615, -0.55861, -0.05639]])\n",
        "  YUVframe = np.matmul(imagearray, transform_matrix)\n",
        "  y, u, v = cv2.split(YUVframe)\n",
        "\n",
        "  # Downsamples/Upsamples\n",
        "  dim_down = (int(u.shape[1] / 2), int(u.shape[0] / 2))\n",
        "  dim_up = (int(u.shape[1]), int(u.shape[0]))\n",
        "  \n",
        "  u_comp = cv2.resize(cv2.resize(u, dim_down), dim_up)\n",
        "  v_comp = cv2.resize(cv2.resize(v, dim_down), dim_up)\n",
        "\n",
        "  YUVframe = cv2.merge((y, u_comp, v_comp))\n",
        "  return YUVframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9sGi7LL0eiw"
      },
      "source": [
        "Task 1. Cut\n",
        "\n",
        "Segment the frame into patches with a patch size of 8x8 pixels by\n",
        "completing the function ‘Image2Patch’ which segments an image\n",
        "into a number of patches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y6r_X8be_Nab"
      },
      "outputs": [],
      "source": [
        "#CUT\n",
        "def Cutimage(frame):\n",
        "  # Cuts a frame into pieces\n",
        "  # Input a black and white frame\n",
        "  # Output the input, cut into 8x8 pixel patches organized in a 'pile'\n",
        "  # of patches. Estimated dimensions: 8x8xmany\n",
        "\n",
        "  pile_list = []\n",
        "  for i in range(0, frame.shape[0], 8):\n",
        "    for j in range(0, frame.shape[1], 8):\n",
        "        pile_list.append(frame[i:i+8, j:j+8])\n",
        "\n",
        "  return pile_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpZ-CCC9Zpc"
      },
      "source": [
        "Task 2. Switch domains\n",
        "\n",
        "Convert each image patch into a vector of DCT coefficients using the\n",
        "function DCTconv. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q3EJXjOpChKp"
      },
      "outputs": [],
      "source": [
        "#DCT\n",
        "def DCTconv(patch):\n",
        "\n",
        "  patch -= 128\n",
        "  patch.astype(np.float32)\n",
        "  conv_patch = cv2.dct(patch)\n",
        "  \n",
        "  # Performs DCT conversion on a frame\n",
        "  # Input a patch\n",
        "  # Output a converted patch\n",
        "\n",
        "  return conv_patch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDgyI0Y0wDt"
      },
      "source": [
        "Task 3. Compress\n",
        "\n",
        "Finish the function iDCTconv. It should perform two operations on a patch:\n",
        "1. Quantize the DCT patch. You are free to come up with your own method of quantization. However, you should have the ability to adjust the level of compression and perform harder compression on 'less valuable' frequencies. Think about which frequencies we want to compress less, and which are not as important!\n",
        "2. Perform inverse DCT conversion on the patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GwzrKblbC5DX"
      },
      "outputs": [],
      "source": [
        "#IDCT\n",
        "def iDCTconv(patch):\n",
        "  # Input should be de-normalized before iDCT, think about what may occur if you put normalized values\n",
        "  \n",
        "  # Performs quantization and inverse DCT\n",
        "  # Input a converted patch\n",
        "  # Output a patch\n",
        "  inverted_patch = []\n",
        "\n",
        "  Q = np.array([[16, 11, 10, 16, 24, 40, 51, 61], [12, 12, 14, 19, 26, 58, 60, 55], [14, 13, 16, 24, 40, 57, 69, 56], [14, 17, 22, 29, 51, 87, 80, 62], [18, 22, 37, 56, 68, 109, 103, 77], [24, 35, 55, 64, 81, 104, 113, 92], [49, 64, 78, 87, 103, 121, 120, 101], [72, 92, 95, 98, 112, 100, 103, 99]])\n",
        "  quantized_patch = np.trunc(patch/Q)\n",
        "\n",
        "  #reversing the quantization\n",
        "  patch = quantized_patch*(Q)\n",
        "\n",
        "  #preforming the inverse cosine transform\n",
        "  patch = cv2.idct(patch)\n",
        "  \n",
        "  \"\"\" for part in patch:\n",
        "    print(part)\n",
        "    for i in range(8):\n",
        "      for j in range(8):\n",
        "        part[i][j] = np.rint(part[i][j] / quantization_matrix[i][j]) * quantization_matrix[i][j]\n",
        "\n",
        "    print(part)\n",
        "    part += 128\n",
        "    part = cv2.idct(part)\n",
        "    inverted_patch.append(part) \"\"\"\n",
        "\n",
        "  return patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irO0QZKU-bht"
      },
      "source": [
        "Task 4. Paste\n",
        "\n",
        "Assemble all patches into a reconstructed frame by the function\n",
        "Patch2Image, display the frame and calculate the PSNR of\n",
        "reconstructed frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tygzHt97DbaS"
      },
      "outputs": [],
      "source": [
        "#PASTE\n",
        "def Pasteimage(pileopatches):\n",
        "  \n",
        "  print('your code here')\n",
        "  \n",
        "  # Puts a pile of patches together into a frame\n",
        "  # Input a pile of patches, estimated dimensions: 8x8xmany\n",
        "  # Output a black and white frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5JwEkMpIgrh"
      },
      "source": [
        "You will also need this to finish the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZmpIct0IZOH"
      },
      "outputs": [],
      "source": [
        "#PSNR\n",
        "def CalculatePSNR(im1, im2): \n",
        "\n",
        "# This function calculates the PSNR between two colour images, im1, im2\n",
        "# You can use numpy.shape to check if two images are of the same size\n",
        "# otherwise you can for example use numpy.resize to make them match\n",
        "# PSNR should be in dB\n",
        "\n",
        "#Put your code from the PSNR block from previous assignments here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjiEn_23021S"
      },
      "source": [
        "#Report\n",
        "\n",
        "In your report, you need to \n",
        "1. Print the photo of Y frame 80 and its\n",
        "reconstructed version. Show them side by side and give them clear titles. \n",
        "2. Give PSNR of the reconstructed Y frame 80.\n",
        "3. Your entire notebook, with relevant images and string plotted and printed.\n",
        "4. Submit your report as a single pdf, combined from your report text and your notebook.\n",
        "\n",
        "Upload your report to “Assignments/Project1”.\n",
        "\n",
        "Deadline is 18 May 2021 23:59"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "996wmx8LDYgQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Project-1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8d7d1f59bf78ea7cf998eb9d50ae8f58f41b51d66364e8066d43fe5d3acf92cf"
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
